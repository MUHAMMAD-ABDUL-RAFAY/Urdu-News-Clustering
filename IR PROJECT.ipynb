{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d1ed739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Newsآفریدی کو الوداعی میچ نہ دینا بدقسمتی ہے\n",
      "آفریدی\n",
      "الوداعی\n",
      "آفریدی\n",
      "آفریدی\n",
      "بدقسمتی\n",
      "میچ\n",
      "میچ\n",
      "میچ\n",
      "میچ\n",
      "میچ\n",
      "میچ\n",
      "میچ\n",
      "میچ\n",
      "آفریدی\n",
      "آفریدی\n",
      "الوداعی\n",
      "میچ\n",
      "میچ\n",
      "میچ\n",
      "میچ\n",
      "میچ\n",
      "میچ\n",
      "میچ\n",
      "میچ\n",
      "میچ\n",
      "میچ\n",
      "میچ\n",
      "میچ\n",
      "میچ\n",
      "میچ\n",
      "میچ\n",
      "آفریدی\n",
      "الوداعی\n",
      "میچ\n",
      "بدقسمتی\n",
      "میچ\n",
      "میچ\n",
      "آفریدی\n",
      "میچ\n",
      "آفریدی\n",
      "['شاہد آفریدی کے لیے الوداعی میچ نہیں تقریب', '’آفریدی کو الوداعی میچ نہ دینا بدقسمتی ہے‘']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "from tkinter import *\n",
    "from urduhack import *\n",
    "import subprocess\n",
    "\n",
    "stopwords = []\n",
    "\n",
    "def get_all_headlines(folder_path):\n",
    "    extraWordsinHeadlines = ['.doc','Urdu NEWS dataset\\\\','voa','bbc','dataset','entertainment','sports','miscleneous','politics','\\\\',\"'\"]\n",
    "    headlines = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "#             print(file_path)\n",
    "            for word in extraWordsinHeadlines:\n",
    "                file_path = file_path.replace(word,' ')\n",
    "            headlines.append(file_path.strip())\n",
    "    return headlines\n",
    "\n",
    "def splitwords(headlines):\n",
    "    lugat = []\n",
    "    for headline in headlines:\n",
    "        alfaz = re.split('\\W+',headline)\n",
    "        lugat.append(alfaz)\n",
    "    return lugat\n",
    "\n",
    "\n",
    "def readstopwords(file_name):\n",
    "    global stopwords\n",
    "    with open(file_name, \"r\",encoding='utf-8') as f:\n",
    "        stopwords = [line.strip() for line in f.readlines()]\n",
    "    return stopwords\n",
    "\n",
    "\n",
    "def removeStopWords(words):\n",
    "    #106033 -> 4571 after stopwords removal\n",
    "    file_name = 'StopWordsUrduList.txt'\n",
    "    stopwords = readstopwords(file_name)\n",
    "    wordswithoutstopwords = []\n",
    "    for outer in words:\n",
    "        for word in outer:\n",
    "            if (word not in stopwords or word != '') and (word not in wordswithoutstopwords):\n",
    "                wordswithoutstopwords.append(word)\n",
    "    return wordswithoutstopwords\n",
    "                \n",
    "    \n",
    "def relatedNews(dataset,inputnews):\n",
    "    relatedNewsList = []\n",
    "    t = 0.5\n",
    "    datasetlist = dataset\n",
    "    ni = inputnews\n",
    "    sizeofdatasetlist = len(datasetlist)\n",
    "    for j in range(0,sizeofdatasetlist):\n",
    "        nj = datasetlist[j]\n",
    "        Sij = getSimilarityScore(ni,nj)\n",
    "        if Sij >= t:\n",
    "            relatedNewsList.append(nj)\n",
    "    print(relatedNewsList)\n",
    "    return relatedNewsList\n",
    "    \n",
    "    \n",
    "\n",
    "def getTokensList(n):\n",
    "    wordsWoSW = []\n",
    "    words = []\n",
    "    words = normalize(n)\n",
    "    words = re.split('\\W+',words)\n",
    "    for word in words:\n",
    "        if word in stopwords:\n",
    "            continue\n",
    "        wordsWoSW.append(word)\n",
    "        \n",
    "    return wordsWoSW\n",
    "\n",
    "    \n",
    "    \n",
    "def getSimilarityScore(ni,nj):\n",
    "    tli = getTokensList(ni)\n",
    "    tlj = getTokensList(nj)\n",
    "    sti = len(tli)\n",
    "    stj = len(tlj)\n",
    "    Sij = 0\n",
    "    mij = 0\n",
    "    \n",
    "    for x in range(0,sti):\n",
    "        for y in range(0,stj):\n",
    "            if tli[x] == tlj[y]:\n",
    "                print(tli[x])\n",
    "                mij = mij + 1\n",
    "    \n",
    "    if mij > 0:\n",
    "        avg = (sti + stj)/2\n",
    "        Sij = mij / avg\n",
    "    \n",
    "    return Sij\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # example usage\n",
    "    inputnews = input(\"Enter News\")\n",
    "    folder_path = 'Urdu NEWS dataset\\\\'\n",
    "    headlines = get_all_headlines(folder_path)\n",
    "    words = splitwords(headlines)\n",
    "    refinedwords = removeStopWords(words)\n",
    "    cluster = relatedNews(headlines,inputnews)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
